{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter-keras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMogVYONLqPC0qIhFkU01eh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/davis-contest/blob/main/colabs/starter_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9MDnS5kwVze"
      },
      "source": [
        "# Instructions and Starter Code for Submitting Results in the DAVIS Contest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHSX1I__VJSW"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install wandb\n",
        "!pip install --ignore-installed git+https://github.com/wandb/davis-contest.git#egg=contest\n",
        "!pip install ptflops pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxaxWQGxU9pi"
      },
      "source": [
        "import os \r\n",
        "\r\n",
        "import wandb\r\n",
        "\r\n",
        "import contest\r\n",
        "from contest.utils import clips, paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtUNLAmqze-T"
      },
      "source": [
        "## 0️⃣ Create a Weights & Biases account if you don't have one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHogIiFVhXjv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoTHl37XxAS9"
      },
      "source": [
        "## 1️⃣ Download the training data from Weights & Biases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXF0H0kpVRAq"
      },
      "source": [
        "entity = \"charlesfrye\"\r\n",
        "project = \"davis\"\r\n",
        "mode = \"train\"\r\n",
        "tag = \"latest\"\r\n",
        "\r\n",
        "training_data_artifact_name = os.path.join(entity, project, f\"davis2016-{mode}\") + \":\" + tag\r\n",
        "training_data_artifact_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyTXkGNEU8wo"
      },
      "source": [
        "with wandb.init(project=project, job_type=\"download\") as run:\r\n",
        "  training_data_artifact = run.use_artifact(training_data_artifact_name)\r\n",
        "  training_data_dir = training_data_artifact.download()\r\n",
        "  print(\"\\ntraining data downloaded to \" + training_data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw9pYa8vxEGJ"
      },
      "source": [
        "### Viewing the Dataset in Weights & Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-NUi6-DWYZ-"
      },
      "source": [
        "Link to dsviz version, include screenshots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMuifb6FxJlB"
      },
      "source": [
        "## 2️⃣ Define and train a model on the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ZHadq5LAQ1"
      },
      "source": [
        "### Splitting up the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-TLlyygKxZg"
      },
      "source": [
        "print(clips.split_on_clips.__doc__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4a4iHs1Kss6"
      },
      "source": [
        "First, set up the validation split, at a clipwise level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkak4W9n_W1N"
      },
      "source": [
        "def log_holdout_split(data_artifact, train_split_df, holdout_split_df):\r\n",
        "  log_datasplit_artifact(data_artifact, train_split_df, \"train\")\r\n",
        "  log_datasplit_artifact(data_artifact, holdout_split_df, \"holdout\")\r\n",
        "\r\n",
        "\r\n",
        "def log_datasplit_artifact(data_artifact, split_df, splitname, folder=\"wandb\"):\r\n",
        "  dataset_artifact = wandb.Artifact(name=f\"davis2016-split-{splitname}\", type=\"split-data\")\r\n",
        "  path = os.path.join(folder, splitname + \".json\")\r\n",
        "  split_df.to_json(path)\r\n",
        "  dataset_artifact.add_file(path, \"paths.json\")\r\n",
        "\r\n",
        "  wandb.run.log_artifact(dataset_artifact)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQqBg6VQENhV"
      },
      "source": [
        "config = {\"training_fraction\": 0.8}\r\n",
        "\r\n",
        "with wandb.init(project=project,\r\n",
        "                job_type=\"split-data\", config=config) as run:\r\n",
        "  training_data_artifact = run.use_artifact(training_data_artifact_name)\r\n",
        "  paths_df = paths.artifact_paths(training_data_artifact)\r\n",
        "\r\n",
        "  training_paths_df, holdout_paths_df = clips.split_on_clips(paths_df)\r\n",
        "  log_holdout_split(training_data_artifact,\r\n",
        "                    training_paths_df,\r\n",
        "                    holdout_paths_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab2u0qDYvUXE"
      },
      "source": [
        "### Model Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI0BQGk9pEkc"
      },
      "source": [
        "import tensorflow.keras as keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjVPNJaQG8tj"
      },
      "source": [
        "def make_model(config):\r\n",
        "  model = keras.Sequential(name=config.name)\r\n",
        "  \r\n",
        "  model.add(keras.layers.InputLayer(input_shape=(None, None, 3)))\r\n",
        "  model.add(keras.layers.experimental.preprocessing.Rescaling(1 / 255.))\r\n",
        "  model.add(keras.layers.Conv2D(1, kernel_size=1))\r\n",
        "  model.add(keras.layers.Activation(\"sigmoid\"))\r\n",
        "  \r\n",
        "  model.compile(optimizer=\"sgd\", loss=\"bce\")\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPt3qidL7sIN"
      },
      "source": [
        "For a more realistic model, see _this notebook_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF4sq2BrKaZk"
      },
      "source": [
        "### Training Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCj56rvLEh1"
      },
      "source": [
        "#### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hia3dlPkefU1"
      },
      "source": [
        "model_artifact_name = \"dummy-baseline-keras\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFKaT-Fr0Ad6"
      },
      "source": [
        "config = {\"batch_size\": 32,\r\n",
        "          \"max_epochs\": 1,\r\n",
        "          \"name\": model_artifact_name}\r\n",
        "\r\n",
        "with wandb.init(project=project, config=config, job_type=\"train\") as run:\r\n",
        "\r\n",
        "  config = wandb.config\r\n",
        "  training_data_artifact = run.use_artifact(training_data_artifact_name)\r\n",
        "  training_data_artifact.download()\r\n",
        "\r\n",
        "  trainsplit_artifact = run.use_artifact(\"davis2016-split-train:latest\")\r\n",
        "  trainsplit_paths = paths.get_paths(trainsplit_artifact)\r\n",
        "\r\n",
        "  holdoutsplit_artifact = run.use_artifact(\"davis2016-split-holdout:latest\")\r\n",
        "  holdoutsplit_paths = paths.get_paths(holdoutsplit_artifact)\r\n",
        "\r\n",
        "  training_data = contest.keras.data.VidSegDatasetSequence(\r\n",
        "    trainsplit_paths[\"raw\"], trainsplit_paths[\"annotation\"], batch_size=config.batch_size)\r\n",
        "  holdout_data = contest.keras.data.VidSegDatasetSequence(\r\n",
        "    holdoutsplit_paths[\"raw\"], holdoutsplit_paths[\"annotation\"], batch_size=config.batch_size)\r\n",
        "\r\n",
        "  model = make_model(config=config)\r\n",
        "\r\n",
        "  model.fit(training_data, epochs=config.max_epochs,\r\n",
        "            validation_data=holdout_data,\r\n",
        "            callbacks=[wandb.keras.WandbCallback()]\r\n",
        "  )\r\n",
        "\r\n",
        "  wandb.config[\"nparams\"] = contest.keras.profile.count_params(model)\r\n",
        "  wandb.config[\"nflops\"] = contest.keras.profile.count_flops(\r\n",
        "    model, training_data[0][0])\r\n",
        "\r\n",
        "  model_artifact_id = contest.keras.utils.save_model_to_artifact(\r\n",
        "    os.path.join(wandb.run.dir, \"model-best.h5\"), model_artifact_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7gj0eF8yc2S"
      },
      "source": [
        "## 3️⃣ Run your model on the evaluation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oleltn0vzS6o"
      },
      "source": [
        "Once you've run your model on the evaluation data,\r\n",
        "there's two steps to submission:\r\n",
        "\r\n",
        "1. Log an \"evaluation run\" to W&B, using _this notebook_.\r\n",
        "2. Submit the results to _the benchmark_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMCkpXv2xCr1"
      },
      "source": [
        "Describe format of the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xg9fMtO1OJ"
      },
      "source": [
        "evaluation_artifact_name = os.path.join(entity, project, \"davis2016-val\" +\":\" + tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ISco63Px4H"
      },
      "source": [
        "model_tag = \"latest\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfZP5_TWdyh1"
      },
      "source": [
        "output_dir = os.path.join(\"outputs\")\r\n",
        "!rm -rf output_dir\r\n",
        "!mkdir -p {output_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcPArWlSeR9t"
      },
      "source": [
        "result_artifact_name = model_artifact_name + \"-result\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkNEH5zOOIJ-"
      },
      "source": [
        "with wandb.init(project=project, job_type=\"run-val\") as run:\r\n",
        "  evaluation_data_artifact = run.use_artifact(evaluation_artifact_name)\r\n",
        "  evaluation_data_paths = paths.artifact_paths(evaluation_data_artifact)\r\n",
        "\r\n",
        "  evaluation_dataset = contest.keras.data.VidSegDatasetSequence(\r\n",
        "    evaluation_data_paths[\"raw\"])\r\n",
        "  num_images = len(evaluation_dataset.image_paths)\r\n",
        "\r\n",
        "  model = contest.keras.utils.load_model_from_artifact(\r\n",
        "    model_artifact_name + \":\" + model_tag)\r\n",
        "\r\n",
        "  print(\"\\n\")\r\n",
        "  nparams = model.count_params()\r\n",
        "  nflops = contest.keras.profile.count_flops(model, evaluation_dataset[0])\r\n",
        "\r\n",
        "  wandb.log({\"nparams\": nparams, \"nflops\": nflops})\r\n",
        "\r\n",
        "  output_paths = contest.keras.evaluate.run(\r\n",
        "    model, evaluation_dataset, num_images, output_dir)\r\n",
        "\r\n",
        "  result_artifact = contest.evaluate.make_result_artifact(\r\n",
        "    output_paths, result_artifact_name)\r\n",
        "  run.log_artifact(result_artifact)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xQDEuHMzNjp"
      },
      "source": [
        "## 4️⃣ Submit your results to the leaderboard on Weights & Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGn2Y9wUU2W9"
      },
      "source": [
        "Once you've run an evaluation job like the one above and produced a results Artifact,\r\n",
        "you're almost ready to submit to the contest.\r\n",
        "\r\n",
        "Head over to _this notebook_ for the last two steps."
      ]
    }
  ]
}